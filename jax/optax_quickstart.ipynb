{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def loss(x, x0):\n",
    "    r = x - x0\n",
    "    return jnp.sum(r ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x10fdb0fe0>, update=<function chain.<locals>.update_fn at 0x10fdb1080>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optax\n",
    "\n",
    "optimizer = optax.adamw(learning_rate=1e-3)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 2.,  0., -2.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "# x0 and x could be any point, e.g. np.zeros((5,), dtype=float)\n",
    "x0 = jnp.array([-1., 0., 1.])\n",
    "x = jnp.array([0., 0., 0.])\n",
    "\n",
    "# Gradient with respect to x. x0 is treated as constant.\n",
    "grad_loss = jax.grad(loss, argnums=0)\n",
    "grad = grad_loss(x, x0)\n",
    "grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ScaleByAdamState(count=Array(0, dtype=int32), mu=Array([0., 0., 0.], dtype=float32), nu=Array([0., 0., 0.], dtype=float32)),\n",
       " EmptyState(),\n",
       " EmptyState())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_state = optimizer.init(x)\n",
    "optimizer_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.00099999, -0.        ,  0.00099999], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(ScaleByAdamState(count=Array(1, dtype=int32), mu=Array([ 0.2,  0. , -0.2], dtype=float32), nu=Array([0.004, 0.   , 0.004], dtype=float32)),\n",
       " EmptyState(),\n",
       " EmptyState())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updates, optimizer_state = optimizer.update(grad, optimizer_state, x)\n",
    "display(updates)\n",
    "display(optimizer_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.00099999,  0.        ,  0.00099999], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = optax.apply_updates(x, updates)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00199996  0.          0.00199996]\n",
      "[-0.10017119  0.          0.10017119]\n",
      "[-0.19332755  0.          0.19332755]\n",
      "[-0.28124353  0.          0.28124353]\n",
      "[-0.36382174  0.          0.36382174]\n",
      "[-0.44096917  0.          0.44096917]\n",
      "[-0.5126047  0.         0.5126047]\n",
      "[-0.578666  0.        0.578666]\n",
      "[-0.63911706  0.          0.63911706]\n",
      "[-0.69395846  0.          0.69395846]\n",
      "[-0.74323493  0.          0.74323493]\n",
      "[-0.78704435  0.          0.78704435]\n",
      "[-0.8255418  0.         0.8255418]\n",
      "[-0.8589458  0.         0.8589458]\n",
      "[-0.88753575  0.          0.88753575]\n",
      "[-0.9116481  0.         0.9116481]\n",
      "[-0.9316673  0.         0.9316673]\n",
      "[-0.9480142  0.         0.9480142]\n",
      "[-0.9611299  0.         0.9611299]\n",
      "[-0.9714603  0.         0.9714603]\n",
      "[-0.9794408  0.         0.9794408]\n",
      "[-0.9854826  0.         0.9854826]\n",
      "[-0.9899609  0.         0.9899609]\n",
      "[-0.9932073  0.         0.9932073]\n",
      "[-0.9955071  0.         0.9955071]\n",
      "[-0.9970973  0.         0.9970973]\n",
      "[-0.99816936  0.          0.99816936]\n",
      "[-0.99887353  0.          0.99887353]\n",
      "[-0.99932295  0.          0.99932295]\n",
      "[-0.9996019  0.         0.9996019]\n"
     ]
    }
   ],
   "source": [
    "# Putting everything together\n",
    "for i in range(3000):\n",
    "    grad = grad_loss(x, x0)\n",
    "    updates, optimizer_state = optimizer.update(grad, optimizer_state, x)\n",
    "    x = optax.apply_updates(x, updates)\n",
    "    if i % 100 == 0:\n",
    "        print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_12_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
