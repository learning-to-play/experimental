{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "import optax\n",
    "\n",
    "\n",
    "vocab_size = 64\n",
    "batch_size = 8\n",
    "block_size = 2048\n",
    "n_embd = 2048\n",
    "head_size = 2048\n",
    "\n",
    "\n",
    "class QKV(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, training=True, kvcache=None):\n",
    "        kvcache_enabled = kvcache is not None\n",
    "        inference_with_kvcache_enabled = not training and kvcache_enabled\n",
    "        if inference_with_kvcache_enabled:\n",
    "            x = x[:, -1:, :]\n",
    "\n",
    "        q = nn.Dense(head_size, use_bias=False)(x)\n",
    "        k = nn.Dense(head_size, use_bias=False)(x)\n",
    "        v = nn.Dense(head_size, use_bias=False)(x)\n",
    "\n",
    "        if inference_with_kvcache_enabled:\n",
    "            if kvcache:\n",
    "                k = jnp.concatenate((kvcache['k'], k), axis=1)[:, -block_size:, :]\n",
    "                v = jnp.concatenate((kvcache['v'], v), axis=1)[:, -block_size:, :]\n",
    "            kvcache['k'] = k\n",
    "            kvcache['v'] = v\n",
    "\n",
    "        return q, k, v\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, context, training=True, kvcache=None):\n",
    "        context_block = context[:, -block_size:]\n",
    "        tok_embed = nn.Embed(vocab_size, n_embd)(context_block)\n",
    "        pos = jnp.arange(0, context_block.shape[1])\n",
    "        pos_embed = nn.Embed(block_size, n_embd)(pos)\n",
    "        x = tok_embed + pos_embed\n",
    "\n",
    "        _kvcache = kvcache\n",
    "        if not training and kvcache is not None:\n",
    "            if 'qkv' not in kvcache:\n",
    "                kvcache['qkv'] = {}\n",
    "            _kvcache = kvcache['qkv']\n",
    "        q, k, v = QKV()(x, training=training, kvcache=_kvcache)\n",
    "\n",
    "        wei = q @ jnp.transpose(k, (0, -1, -2))\n",
    "        wei = nn.softmax(wei, axis=-1)\n",
    "        out = wei @ v\n",
    "        logits = nn.Dense(vocab_size)(out)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, params, context, labels, training):\n",
    "        logits = self.apply(params, context, training=training)\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "\n",
    "    def generate(self, prng_key, params, context, max_new_tokens=1, use_kvcache=True):\n",
    "        kvcache = {} if use_kvcache else None\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self.apply(params, context, training=False, kvcache=kvcache)[:, -1, :]\n",
    "            prng_key, prng_subkey = random.split(prng_key)\n",
    "            context_next = random.categorical(prng_subkey, logits)\n",
    "            context = jnp.concatenate((context, jnp.reshape(context_next, (-1, 1))), axis=1)\n",
    "        return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Head()\n",
    "prng_key = random.key(0)\n",
    "context = jnp.zeros((1, 1), dtype=int)\n",
    "params = model.init(prng_key, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 5\n",
    "\n",
    "optimizer = optax.adamw(learning_rate=1e-3)\n",
    "params = model.init(prng_key, jnp.zeros((1, block_size), dtype=int), training=True)\n",
    "optimizer_state = optimizer.init(params)\n",
    "\n",
    "grad_loss = jax.grad(model.loss, argnums=0)\n",
    "\n",
    "context = random.randint(prng_key, (batch_size, block_size), 0, vocab_size)\n",
    "labels = random.randint(prng_key, (batch_size, block_size), 0, vocab_size)\n",
    "\n",
    "for i in range(max_iters):\n",
    "    print(f\"Iteration: {i}\")\n",
    "    grad = grad_loss(params, context, labels, training=True)\n",
    "    updates, optimizer_state = optimizer.update(grad, optimizer_state, params)\n",
    "    params = optax.apply_updates(params, updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def run_timeit(f, x):\n",
    "    result = %timeit -o f(x)\n",
    "    return result\n",
    "\n",
    "max_new_tokens = [100, 200, 300, 400]\n",
    "\n",
    "_ = model.generate(prng_key, params, context, 1, use_kvcache=False)\n",
    "generator = lambda n: model.generate(prng_key, params, context, n, use_kvcache=False)\n",
    "timeits_nocache = [run_timeit(generator, n) for n in max_new_tokens]\n",
    "\n",
    "_ = model.generate(prng_key, params, context, 1, use_kvcache=True)\n",
    "generator = lambda n: model.generate(prng_key, params, context, n, use_kvcache=True)\n",
    "timeits_kvcache = [run_timeit(generator, n) for n in max_new_tokens]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(max_new_tokens, [t.average for t in timeits_nocache])\n",
    "plt.plot(max_new_tokens, [t.average for t in timeits_kvcache])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. If I run the training before serving, the serving will take an extremely long time. Why?\n",
    "1. Starting input context may be [0, 1, 2].\n",
    "1. What happens when there are multiple layers?\n",
    "1. How to simplify code? For example, can we remove `if training`, not use `block_size` or `T`, and avoid using `if`?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_12_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
